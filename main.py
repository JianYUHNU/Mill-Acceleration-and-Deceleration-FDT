"""
main.py
FDT å‡ºå£æ¸©åº¦å›å½’
1. è‡ªåŠ¨å‰”é™¤æ— å…³åˆ—ï¼ˆæ‰‹åŠ¨ + ç»Ÿè®¡è§„åˆ™ï¼‰
2. è®­ç»ƒ / éªŒè¯ / TensorBoard / torchinfo
3. æƒé‡è‡ªåŠ¨åŠ è½½æˆ–é‡æ–°è®­ç»ƒ
"""
import os, glob, datetime
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from torch.utils.tensorboard import SummaryWriter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import VarianceThreshold
from tqdm import tqdm
from torchinfo import summary

# --------------------------------------------------
# 1. è·¯å¾„
# --------------------------------------------------
ROOT_DIR    = r"C:\Users\ç®€è¯­\Desktop\è½§æœºå‡é€Ÿé™é€ŸFDT"
SAVE_DIR    = "runs"
WEIGHT_PATH = "best_model.pt"
os.makedirs(SAVE_DIR, exist_ok=True)

# --------------------------------------------------
# 2. æ‰‹åŠ¨å‰”é™¤åˆ—è¡¨
# --------------------------------------------------
MANUAL_DROP = [
    "Date", "Time", "Milli Sec",
    "L_FMTSTODG_10", "L_FM_F7SFBMS", "L_FM_F6MSUC",
    "L_FM_MRH_MANACC", "L_FM_MRH_MANDEC",
    "L_MPD069PL_SL", "L_MPD070PL_SL", "L_MPD071PL_SL",
    "L_SUC_F5TSUC", "L_SUC_F6TSUC"
]
TARGET_COL  = "L_YP09BT11_IF"

# --------------------------------------------------
# 3. è¯»å– & åˆå¹¶ CSV
# --------------------------------------------------
all_csv = [sorted(glob.glob(os.path.join(ROOT_DIR, d, "*.csv")))[0]
           for d in os.listdir(ROOT_DIR)
           if os.path.isdir(os.path.join(ROOT_DIR, d))]
df_list = [pd.read_csv(f).select_dtypes(include=[np.number]) for f in tqdm(all_csv, desc="è¯»å– CSV")]
df = pd.concat(df_list, ignore_index=True)

# --------------------------------------------------
# 4. ç‰¹å¾è‡ªåŠ¨é€‰æ‹©ï¼ˆå·²ä¿®å¤å¸ƒå°”ç´¢å¼•é•¿åº¦é—®é¢˜ï¼‰
# --------------------------------------------------
def auto_select(df, target_col, manual_drop, var_thresh=1e-4, corr_thresh=0.01):
    """è¿”å› (clean_df, kept_columns)"""
    # 1. æ‰‹åŠ¨å‰”é™¤
    df = df.drop(columns=manual_drop, errors='ignore')

    # 2. ç¼ºå¤±ç‡ >1% å‰”é™¤
    df = df.loc[:, df.isnull().mean() < 0.01]

    # 3. æ–¹å·®é˜ˆå€¼ï¼ˆä»…å¯¹ç‰¹å¾ï¼‰
    X_df = df.drop(columns=[target_col])
    selector = VarianceThreshold(threshold=var_thresh)
    selector.fit(X_df)
    X_df = X_df.loc[:, selector.get_support()]

    # 4. ä¸å› å˜é‡ç›¸å…³æ€§é˜ˆå€¼
    corr = X_df.corrwith(df[target_col]).abs()
    keep_mask = corr > corr_thresh
    X_df = X_df.loc[:, keep_mask]

    # 5. åŠ å›ç›®æ ‡åˆ—
    clean_df = pd.concat([X_df, df[target_col]], axis=1)
    return clean_df, X_df.columns.tolist()

df_clean, kept_features = auto_select(df, TARGET_COL, MANUAL_DROP)
print(f"åŸå§‹ç‰¹å¾æ•°ï¼š{df.shape[1]-1} â†’ ä¿ç•™ç‰¹å¾æ•°ï¼š{len(kept_features)}")
pd.Series(kept_features).to_csv("selected_features.csv", index=False, header=False)

# --------------------------------------------------
# 5. PyTorch æ•°æ®å‡†å¤‡
# --------------------------------------------------
X = df_clean.drop(columns=[TARGET_COL]).values.astype(np.float32)
y = df_clean[TARGET_COL].values.astype(np.float32).reshape(-1, 1)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val   = scaler.transform(X_val)

train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))
val_ds   = TensorDataset(torch.from_numpy(X_val),   torch.from_numpy(y_val))
train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)
val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)

# --------------------------------------------------
# 6. æ¨¡å‹
# --------------------------------------------------
class FDTRegressor(nn.Module):
    def __init__(self, in_features):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_features, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
    def forward(self, x):
        return self.net(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = FDTRegressor(in_features=X.shape[1]).to(device)

# --------------------------------------------------
# 7. æƒé‡åŠ è½½ / è®­ç»ƒ
# --------------------------------------------------
if os.path.isfile(WEIGHT_PATH):
    print("âœ… æ£€æµ‹åˆ°æƒé‡æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½...")
    model.load_state_dict(torch.load(WEIGHT_PATH, map_location=device))
else:
    print("ğŸ‘‰ æƒé‡ä¸å­˜åœ¨ï¼Œå¼€å§‹è®­ç»ƒ...")

    run_tag = datetime.datetime.now().strftime("%m%d_%H%M")
    writer = SummaryWriter(log_dir=os.path.join(SAVE_DIR, f"run_{run_tag}"))
    dummy = torch.randn(1, X.shape[1]).to(device)
    writer.add_graph(model, dummy)

    criterion = nn.L1Loss()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    best_val = float("inf")

    EPOCHS = 100
    global_step = 0
    for epoch in range(1, EPOCHS + 1):
        model.train()
        train_loss = 0.0
        pbar = tqdm(train_loader, desc=f"Epoch {epoch:03d}")
        for xb, yb in pbar:
            xb, yb = xb.to(device), yb.to(device)
            pred = model(xb)
            loss = criterion(pred, yb)
            optimizer.zero_grad(); loss.backward(); optimizer.step()
            train_loss += loss.item() * xb.size(0)
            writer.add_scalar("Loss/train_step", loss.item(), global_step)
            global_step += 1
            pbar.set_postfix(loss=loss.item())
        train_loss /= len(train_loader.dataset)
        writer.add_scalar("Loss/train_epoch", train_loss, epoch)

        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for xb, yb in val_loader:
                xb, yb = xb.to(device), yb.to(device)
                pred = model(xb)
                val_loss += criterion(pred, yb).item() * xb.size(0)
        val_loss /= len(val_loader.dataset)
        writer.add_scalar("Loss/val_epoch", val_loss, epoch)

        tqdm.write(f"Epoch {epoch:03d} | "
                   f"Train MAE {train_loss:.4f} | Val MAE {val_loss:.4f}")
        if val_loss < best_val:
            best_val = val_loss
            torch.save(model.state_dict(), WEIGHT_PATH)
            tqdm.write("âœ… å·²ä¿å­˜ best_model.pt")
    writer.close()
    print("è®­ç»ƒå®Œæˆï¼")

# --------------------------------------------------
# 8. torchinfo æ‰“å°å‚æ•°
# --------------------------------------------------
print("\n========== Model Summary ==========")
summary(model, input_size=(1, X.shape[1]), device=str(device))

# --------------------------------------------------
# 9. æç¤º
# --------------------------------------------------
print("\nè‹¥æƒ³æŸ¥çœ‹å¯è§†åŒ–ï¼Œè¯·åœ¨ç»ˆç«¯æ‰§è¡Œï¼š")
print(f"tensorboard --logdir {os.path.abspath(SAVE_DIR)}")